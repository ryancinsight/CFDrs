//! GPU-accelerated matrix-free linear solvers.
//! Temporarily disabled to focus on core DG functionality.

/*
use super::operator::{GpuLinearOperator, LinearOperator};
use super::traits::MatrixFreeSolver;
use crate::linear_solver::{
    config::IterativeSolverConfig,
    matrix_free::{
        operator::{GpuLinearOperator, LinearOperator},
        traits::MatrixFreeSolver,
    },
    LinearSolver,
};
use cfd_core::compute::gpu::{GpuBuffer, GpuContext};
use cfd_core::error::{Error, Result};
use nalgebra::{DVector, RealField};
use num_traits::FromPrimitive;
use std::fmt::Debug;
use std::sync::Arc;

/// GPU-accelerated GMRES solver for matrix-free operators.
pub struct GpuMatrixFreeGMRES<T: RealField + Copy + bytemuck::Pod + bytemuck::Zeroable> {
    cpu_solver: super::gmres::MatrixFreeGMRES<T>,
    gpu_context: Option<Arc<GpuContext>>,
}

impl<T: RealField + Copy + bytemuck::Pod + bytemuck::Zeroable + FromPrimitive + Debug> GpuMatrixFreeGMRES<T> {
    /// Create a new GPU-accelerated GMRES solver.
    pub fn new(config: IterativeSolverConfig<T>, restart_dim: usize, gpu_context: Option<Arc<GpuContext>>) -> Self {
        let cpu_solver = super::gmres::MatrixFreeGMRES::new(config, restart_dim);
        Self {
            cpu_solver,
            gpu_context,
        }
    }

    /// Create with default configuration.
    pub fn default_with_gpu(gpu_context: Option<Arc<GpuContext>>) -> Self {
        Self::new(IterativeSolverConfig::default(), 30, gpu_context)
    }

    /// Solve using automatic CPU/GPU dispatch.
    pub fn solve_auto<Op: LinearOperator<T> + GpuLinearOperator<T>>(
        &self,
        operator: &Op,
        b: &DVector<T>,
        x: &mut DVector<T>,
    ) -> Result<()> {
        if self.can_use_gpu(operator, b.len()) {
            if let Some(ref ctx) = self.gpu_context {
                return self.solve_gpu(operator, ctx, b, x);
            }
        }
        self.solve_cpu(operator, b, x)
    }

    /// Force CPU execution.
    pub fn solve_cpu<Op: LinearOperator<T>>(&self, operator: &Op, b: &DVector<T>, x: &mut DVector<T>) -> Result<()> {
        self.cpu_solver.solve(operator, b, x)
    }

    /// Force GPU execution (fails if GPU not available).
    pub fn solve_gpu<Op: GpuLinearOperator<T>>(
        &self,
        operator: &Op,
        gpu_context: &Arc<GpuContext>,
        b: &DVector<T>,
        x: &mut DVector<T>,
    ) -> Result<()> {
        // For now, just use CPU fallback
        self.solve_cpu(operator, b, x)
    }

    /// Check if GPU execution should be used.
    fn can_use_gpu<Op: GpuLinearOperator<T>>(&self, operator: &Op, problem_size: usize) -> bool {
        self.gpu_context.is_some() && operator.supports_gpu() && problem_size >= 1000
    }
}

impl<T> Configurable<T> for GpuMatrixFreeGMRES<T>
where
    T: RealField + Copy + bytemuck::Pod + bytemuck::Zeroable + FromPrimitive + Debug,
{
    type Config = IterativeSolverConfig<T>;

    fn config(&self) -> &Self::Config {
        self.cpu_solver.config()
    }
}

impl<T> MatrixFreeSolver<T> for GpuMatrixFreeGMRES<T>
where
    T: RealField + Copy + bytemuck::Pod + bytemuck::Zeroable + FromPrimitive + Debug + Default + From<f64> + 'static,
{
    fn solve(&self, operator: &dyn LinearOperator<T>, b: &[T], x: &mut [T]) -> Result<()> {
        let b_vec = DVector::from_column_slice(b);
        let mut x_vec = DVector::from_column_slice(x);
        
        // For now, just use CPU fallback
        self.cpu_solver.solve(operator, &b_vec, &mut x_vec)?;
        
        x.copy_from_slice(x_vec.as_slice());
        Ok(())
    }
}

/// GPU-accelerated BiCGSTAB solver for matrix-free operators.
pub struct GpuMatrixFreeBiCGSTAB<T>
where
    T: RealField + Copy + bytemuck::Pod + bytemuck::Zeroable + FromPrimitive + Debug + Default + From<f64> + 'static,
{
    cpu_solver: super::bicgstab::MatrixFreeBiCGSTAB<T>,
    gpu_context: Option<Arc<GpuContext>>,
}

impl<T: RealField + Copy + bytemuck::Pod + bytemuck::Zeroable + FromPrimitive + Debug + Default + From<f64> + 'static>
    GpuMatrixFreeBiCGSTAB<T>
{
    /// Create a new GPU-accelerated BiCGSTAB solver.
    pub fn new(config: IterativeSolverConfig<T>) -> Self {
        let cpu_solver = super::bicgstab::MatrixFreeBiCGSTAB::new(config);
        let gpu_context = GpuContext::create().ok();
        Self {
            cpu_solver,
            gpu_context,
        }
    }

    /// Create with default configuration.
    pub fn default_with_gpu(gpu_context: Option<Arc<GpuContext>>) -> Self {
        Self::new(IterativeSolverConfig::default()).with_gpu(gpu_context.is_some())
    }

    /// Solve using automatic CPU/GPU dispatch.
    pub fn solve_auto<Op: LinearOperator<T> + GpuLinearOperator<T>>(
        &self,
        operator: &Op,
        b: &DVector<T>,
        x: &mut DVector<T>,
    ) -> Result<()> {
        if self.can_use_gpu(operator, b.len()) {
            if let Some(ref ctx) = self.gpu_context {
                return self.solve_gpu(operator, ctx, b, x);
            }
        }
        self.solve_cpu(operator, b, x)
    }

    /// Force CPU execution.
    pub fn solve_cpu<Op: LinearOperator<T>>(&self, operator: &Op, b: &DVector<T>, x: &mut DVector<T>) -> Result<()> {
        self.cpu_solver.solve(operator, b, x)
    }

    /// Force GPU execution.
    pub fn solve_gpu<Op: GpuLinearOperator<T>>(
        &self,
        operator: &Op,
        gpu_context: &Arc<GpuContext>,
        b: &DVector<T>,
        x: &mut DVector<T>,
    ) -> Result<()> {
        // For now, just use CPU fallback
        self.solve_cpu(operator, b, x)
    }

    /// Check if GPU execution should be used.
    fn can_use_gpu<Op: GpuLinearOperator<T>>(&self, operator: &Op, problem_size: usize) -> bool {
        self.gpu_context.is_some() && operator.supports_gpu() && problem_size >= 1000
    }

    /// Enable or disable GPU acceleration.
    pub fn with_gpu(mut self, use_gpu: bool) -> Self {
        if !use_gpu {
            self.gpu_context = None;
        } else if self.gpu_context.is_none() {
            self.gpu_context = GpuContext::create().ok();
        }
        self
    }
}

use crate::linear_solver::traits::Configurable as ConfigurableTrait;

impl<T> ConfigurableTrait<T> for GpuMatrixFreeBiCGSTAB<T>
where
    T: RealField + Copy + bytemuck::Pod + bytemuck::Zeroable + FromPrimitive + Debug + Default + From<f64> + 'static,
{
    type Config = <super::bicgstab::MatrixFreeBiCGSTAB<T> as ConfigurableTrait<T>>::Config;

    fn config(&self) -> &Self::Config {
        self.cpu_solver.config()
    }
    
    fn config_mut(&mut self) -> &mut Self::Config {
        self.cpu_solver.config_mut()
    }
}

impl<T> MatrixFreeSolver<T> for GpuMatrixFreeBiCGSTAB<T>
where
    T: RealField + Copy + bytemuck::Pod + bytemuck::Zeroable + FromPrimitive + Debug + Default + From<f64> + 'static,
{
    fn solve(&self, operator: &dyn LinearOperator<T>, b: &[T], x: &mut [T]) -> Result<()> {
        let b_vec = DVector::from_column_slice(b);
        let mut x_vec = DVector::from_column_slice(x);
        
        // For now, just use CPU fallback
        self.cpu_solver.solve(operator, &b_vec, &mut x_vec)?;
        
        x.copy_from_slice(x_vec.as_slice());
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use approx::assert_relative_eq;
    use nalgebra::DVector;

    #[test]
    fn test_gpu_gmres_creation() {
        let _solver = GpuMatrixFreeGMRES::<f64>::default_with_gpu(None);
    }

    #[test]
    fn test_gpu_bicgstab_creation() {
        let _solver = GpuMatrixFreeBiCGSTAB::<f64>::default_with_gpu(None);
    }

    #[test]
    fn test_cpu_fallback() -> Result<()> {
        use crate::linear_solver::matrix_free::operator::IdentityOperator;
        
        let solver = GpuMatrixFreeBiCGSTAB::<f64>::default_with_gpu(None);
        let op = IdentityOperator::new(5);
        let b = DVector::from_element(5, 1.0);
        let mut x = DVector::zeros(5);
        
        solver.solve(&op, b.as_slice(), x.as_mut_slice())?;
        assert_relative_eq!(x, b, epsilon = 1e-10);
        
        Ok(())
    }
}
*/
